# graph/graph_builder.py - Ø¨Ø³ÙŠØ· Ø¨Ø¯ÙˆÙ† tools

import sys
import os

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ù…Ø³Ø§Ø±
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from langgraph.graph import StateGraph, START, END
from .llm_node import llm_node, State
from swagger.config import LLMConfig
from langchain_openai import ChatOpenAI

def build_graph():
    """Ø¨Ù†Ø§Ø¡ graph Ø¨Ø³ÙŠØ· Ø¨Ø¯ÙˆÙ† tools"""
    
    print("ğŸ—ï¸ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ graph...")
    
    graph_builder = StateGraph(State)
    llm_conf = LLMConfig()
    llm = ChatOpenAI(temperature=llm_conf.TEMPERATURE, model=llm_conf.MODEL_NAME)
    
    print("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ChatOpenAI Ø¨Ù†Ø¬Ø§Ø­!")
    
    # Ø¹Ù‚Ø¯Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· - llm Ø°ÙƒÙŠ
    graph_builder.add_node("llm", lambda state: llm_node(state, llm))
    
    # ØªÙˆØµÙŠÙ„ Ø¨Ø³ÙŠØ·: START â†’ llm â†’ END
    graph_builder.add_edge(START, "llm")
    graph_builder.add_edge("llm", END)
    
    graph = graph_builder.compile()
    print("âœ… ØªÙ… Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ graph Ø¨Ù†Ø¬Ø§Ø­!")
    
    return graph

# Ø§Ø®ØªØ¨Ø§Ø±
def test_graph():
    try:
        print("ğŸ§ª Testing simple graph...")
        graph = build_graph()
        
        # Ø§Ø®ØªØ¨Ø§Ø± ØªØ´ØºÙŠÙ„
        test_state = {"messages": [("user", "Ø§Ø¨Ø­Ø«Ù„ÙŠ Ø¹Ù† APIs Ù„Ù„Ù…ØµØ§Ø¯Ù‚Ø©")]}
        result = graph.invoke(test_state)
        
        print("ğŸ‰ Graph test successful!")
        print(f"ğŸ“‹ Response preview: {str(result)[:100]}...")
        
        return graph
    except Exception as e:
        print(f"âŒ Graph test failed: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    test_graph()